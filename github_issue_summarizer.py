#!/usr/bin/env python3
"""
GitHub Issue é€Ÿè§ˆå™¨ CLI
æ”¯æŒå¤§æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆä¸€å¥è¯æ‘˜è¦
"""
from __future__ import annotations

import asyncio
import json
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import List

import httpx
import typer
from pydantic import BaseModel
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.table import Table

from config import (
    DONE_KEYWORDS,
    NOISE_LABELS,
    PRIORITY_RULES,
    PRIORITY_STRINGS,
    TYPE_PATTERNS,
)
from llm_summary import summarize_batch
from utils import setup_logger

logger = setup_logger()

# ---------- æ•°æ®æ¨¡å‹ ----------
class Issue(BaseModel):
    """å•ä¸ª GitHub Issue çš„ç»“æ„åŒ–ä¿¡æ¯"""

    number: int
    title: str
    body: str | None
    labels: List[str]
    assignees: List[str]
    state: str
    created_at: datetime
    updated_at: datetime
    html_url: str
    type_: str = ""
    priority: str = ""


# ---------- æ­£åˆ™é¢„ç¼–è¯‘ ----------
TYPE_PATTERNS_COMPILED = {
    k: [re.compile(p, re.I) for p in lst] for k, lst in TYPE_PATTERNS.items()
}
PRIORITY_RULES_COMPILED = {
    k: [re.compile(p, re.I) for p in lst] for k, lst in PRIORITY_RULES.items()
}


# ---------- åˆ†ç±»ä¸è¿‡æ»¤ ----------
def classify_issue(issue: Issue) -> Issue:
    """æ ¹æ®æ ‡é¢˜å’Œæ­£æ–‡æ¨æ–­ issue çš„ç±»å‹ä¸ä¼˜å…ˆçº§"""
    text = f"{issue.title} {issue.body or ''}".lower()

    # ç±»å‹
    for issue_type, patterns in TYPE_PATTERNS_COMPILED.items():
        if any(p.search(text) for p in patterns):
            issue.type_ = issue_type
            break
    else:
        issue.type_ = "Other"

    # ä¼˜å…ˆçº§
    for prio, patterns in PRIORITY_RULES_COMPILED.items():
        if any(p.search(text) for p in patterns):
            issue.priority = prio
            break
        # é¢å¤–æ£€æŸ¥ label é‡Œæ˜¯å¦ç›´æ¥åŒ…å«å­—ç¬¦ä¸²
        if any(s.strip("/") in issue.labels for s in PRIORITY_STRINGS[prio]):
            issue.priority = prio
            break
    else:
        issue.priority = "P2"
    return issue


def should_include(issue: Issue) -> bool:
    """è¿”å› True è¡¨ç¤ºä¿ç•™è¯¥ issue"""
    if issue.state != "open":
        return False
    if issue.assignees:
        return False
    content = f"{issue.title} {issue.body or ''}".lower()
    if any(kw in content for kw in DONE_KEYWORDS):
        return False
    if any(lbl.lower() in map(str.lower, NOISE_LABELS) for lbl in issue.labels):
        return False
    return True


# ---------- æŠ“å– ----------
GITHUB_API = "https://api.github.com"
PER_PAGE = 100
MAX_ITEMS = 10_000


async def fetch_issues(repo: str, token: str | None) -> List[Issue]:
    """æŠ“å–æŒ‡å®šä»“åº“çš„ open issuesï¼Œè‡ªåŠ¨åœäº GitHub ä¸Šé™"""
    headers = {"Accept": "application/vnd.github+json"}
    if token:
        headers["Authorization"] = f"Bearer {token}"

    issues: List[Issue] = []
    page = 1

    async with httpx.AsyncClient(
        http2=True,
        limits=httpx.Limits(max_keepalive_connections=20, max_connections=100),
        timeout=30,
    ) as client:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            transient=True,
            console=Console(stderr=True),
        ) as progress:
            task = progress.add_task("Fetching issues...", total=None)
            while len(issues) < MAX_ITEMS:
                r = await client.get(
                    f"{GITHUB_API}/repos/{repo}/issues",
                    headers=headers,
                    params={
                        "state": "open",
                        "sort": "updated",
                        "direction": "desc",
                        "per_page": PER_PAGE,
                        "page": page,
                    },
                )

                if r.status_code == 404:
                    logger.error("Repository not found")
                    sys.exit(1)
                if r.status_code == 422:
                    logger.info("No more issues (422), stopping.")
                    break
                if r.status_code == 403:
                    logger.error("Rate limit or token error: %s", r.text)
                    sys.exit(1)
                r.raise_for_status()

                data = r.json()
                if not data:
                    break

                for item in data:
                    if "pull_request" in item:
                        continue
                    issue = Issue(
                        number=item["number"],
                        title=item["title"],
                        body=item.get("body") or "",
                        labels=[l["name"] for l in item["labels"]],
                        assignees=[a["login"] for a in item["assignees"]],
                        state=item["state"],
                        created_at=datetime.fromisoformat(
                            item["created_at"].replace("Z", "+00:00")
                        ),
                        updated_at=datetime.fromisoformat(
                            item["updated_at"].replace("Z", "+00:00")
                        ),
                        html_url=item["html_url"],
                    )
                    issue = classify_issue(issue)
                    if should_include(issue):
                        issues.append(issue)

                remain = int(r.headers.get("x-ratelimit-remaining", 1))
                reset_ts = int(r.headers.get("x-ratelimit-reset", 0))
                if remain < 10 and reset_ts:
                    wait = max(reset_ts - int(datetime.now().timestamp()), 0) + 1
                    logger.warning("Rate limit low, sleeping %ds", wait)
                    await asyncio.sleep(wait)

                page += 1
                progress.update(task, advance=PER_PAGE)

    logger.info("Fetched %d issues after filtering", len(issues))
    return issues


# ---------- æ‘˜è¦ & è¾“å‡º ----------
async def build_summary_async(issues: List[Issue], repo: str) -> tuple[str, str]:
    """ç”Ÿæˆé¡¹ç›®æ€»è§ˆä¸ Markdown è¡¨æ ¼"""
    total = len(issues)
    bugs = sum(1 for i in issues if i.type_ == "Bug")
    features = sum(1 for i in issues if i.type_ == "Feature Request")
    scores = {"P0": 0, "P1": 1, "P2": 2}
    avg_score = (
        round(sum(scores.get(i.priority, 2) for i in issues) / total) if total else 2
    )
    latest = (
        max(issues, key=lambda i: i.updated_at).updated_at.strftime("%Y-%m-%d")
        if issues
        else "N/A"
    )
    oneliner = (
        f"{repo} ç›®å‰å…±æœ‰ **{total}** ä¸ªå¾…è§£å†³ Issue"
        f"ï¼ˆBug {bugs} ä¸ª / æ–°åŠŸèƒ½ {features} ä¸ªï¼‰ï¼Œ"
        f"å¹³å‡ä¼˜å…ˆçº§ P{avg_score}ï¼Œæœ€æ–°æ›´æ–°äº {latest}ã€‚"
    )

    summaries = await summarize_batch(issues[:100])
    md_rows = [
        "| #Issue | ç±»å‹ | ä¼˜å…ˆçº§ | æ ‡é¢˜ | ä¸€å¥è¯æ‘˜è¦ | å…³é”®æ ‡ç­¾ | åˆ›å»ºæ—¶é—´ | åœ°å€ |",
        "| --- | --- | --- | --- | --- | --- | --- | --- |",
    ]
    for issue, summary in zip(issues[:100], summaries):
        labels = ", ".join(issue.labels[:3])
        md_rows.append(
            f"| {issue.number} | {issue.type_} | {issue.priority} | {issue.title} "
            f"| {summary} | {labels} | {issue.created_at.date()} "
            f"| [ğŸ”—]({issue.html_url}) |"
        )
    return oneliner, "\n".join(md_rows)


def save_outputs(repo: str, oneliner: str, md_table: str, issues: List[Issue]) -> None:
    """ä¿å­˜ç»“æœåˆ°æœ¬åœ°æ–‡ä»¶"""
    out_dir = Path("output")
    out_dir.mkdir(exist_ok=True)
    summary = f"# {repo} Issues é€Ÿè§ˆ\n\n{oneliner}\n\n{md_table}"
    (out_dir / "summary.md").write_text(summary, encoding="utf-8")
    (out_dir / "filtered_issues.json").write_text(
        json.dumps(
            [i.model_dump(mode="json") for i in issues],
            ensure_ascii=False,
            indent=2,
            default=str,
        ),
        encoding="utf-8",
    )
    console = Console()
    table = Table(title=f"{repo} é€Ÿè§ˆï¼ˆå‰ 20ï¼‰")
    for col in ["#Issue", "ç±»å‹", "ä¼˜å…ˆçº§", "æ ‡é¢˜"]:
        table.add_column(col, overflow="fold", max_width=30)
    for i in issues[:20]:
        table.add_row(str(i.number), i.type_, i.priority, i.title)
    console.print(table)


# ---------- CLI ----------
app = typer.Typer(help="GitHub Issue é€Ÿè§ˆå™¨ï¼ˆæ”¯æŒ LLM æ‘˜è¦ï¼‰")


@app.command()
def main(
    repo: str = typer.Argument(..., help="owner/repo æ ¼å¼"),
    token: str = typer.Option(None, envvar="GH_TOKEN", help="GitHub Token"),
) -> None:
    """ä¸»å…¥å£"""
    asyncio.run(run(repo, token))


async def run(repo: str, token: str | None) -> None:
    """å¼‚æ­¥ä¸»æµç¨‹"""
    issues = await fetch_issues(repo, token)
    oneliner, md_table = await build_summary_async(issues, repo)
    save_outputs(repo, oneliner, md_table, issues)
    typer.echo("âœ… å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ output/")


if __name__ == "__main__":
    app()
